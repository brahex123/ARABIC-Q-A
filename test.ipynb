{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\qa_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"train-open.json\",\n",
    "    \"validation\": \"val-open.json\",\n",
    "    \"test\": \"test-open.json\"\n",
    "}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/aragpt2-base\")\n",
    "\n",
    "# Assign a padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"question\"]\n",
    "    targets = examples[\"answer\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=128, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        targets, max_length=128, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"aubmindlab/aragpt2-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (2.5.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (2.5.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\qa_env\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model1\",          # Save directory\n",
    "    evaluation_strategy=\"epoch\",    # Evaluate at the end of each epoch\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,  # Reduce batch size\n",
    "    num_train_epochs=1,             # Reduce number of epochs\n",
    "    weight_decay=0.01,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",           # Directory for logs\n",
    "    logging_steps=10,\n",
    "    warmup_steps=100,               # Warmup steps for LR scheduler\n",
    "    gradient_accumulation_steps=4,  # Increase gradient accumulation steps\n",
    "    fp16=True,                      # Enable mixed precision\n",
    "    run_name=\"QA-Model\"             # Experiment name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (5.29.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (6.1.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (2.10.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (2.19.2)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (0.20.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\administrator\\anaconda3\\envs\\qa_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_19432\\463571097.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmohammedberrhazi003\u001b[0m (\u001b[33mmohammedberrhazi003-universit-internationale-de-rabat\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\ProjetNlp\\wandb\\run-20241222_112134-n6xsj6vl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mohammedberrhazi003-universit-internationale-de-rabat/huggingface/runs/n6xsj6vl' target=\"_blank\">QA-Model</a></strong> to <a href='https://wandb.ai/mohammedberrhazi003-universit-internationale-de-rabat/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mohammedberrhazi003-universit-internationale-de-rabat/huggingface' target=\"_blank\">https://wandb.ai/mohammedberrhazi003-universit-internationale-de-rabat/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mohammedberrhazi003-universit-internationale-de-rabat/huggingface/runs/n6xsj6vl' target=\"_blank\">https://wandb.ai/mohammedberrhazi003-universit-internationale-de-rabat/huggingface/runs/n6xsj6vl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 10/125 [07:09<1:21:32, 42.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 32.9763, 'grad_norm': 553.0879516601562, 'learning_rate': 2.5e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 20/125 [14:20<1:15:14, 42.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 25.641, 'grad_norm': 555.3907470703125, 'learning_rate': 7.5e-06, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 30/125 [21:26<1:07:00, 42.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.8084, 'grad_norm': 78.3990478515625, 'learning_rate': 1.2e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 40/125 [28:34<1:00:38, 42.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.4925, 'grad_norm': 28.152421951293945, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 50/125 [35:45<54:04, 43.25s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9401, 'grad_norm': 11.791635513305664, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 60/125 [43:16<48:14, 44.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9333, 'grad_norm': 12.258994102478027, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 70/125 [50:40<40:43, 44.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.1303, 'grad_norm': 12.370987892150879, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/125 [58:51<40:47, 54.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.114, 'grad_norm': 18.5513973236084, 'learning_rate': 3.7e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 90/125 [1:07:51<27:56, 47.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.778, 'grad_norm': 7.627808570861816, 'learning_rate': 4.2e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 100/125 [1:16:24<19:52, 47.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6031, 'grad_norm': 8.239971160888672, 'learning_rate': 4.7e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 110/125 [1:23:22<10:14, 40.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3139, 'grad_norm': 5.128443241119385, 'learning_rate': 4.2e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 120/125 [1:30:08<03:22, 40.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5437, 'grad_norm': 11.689654350280762, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [1:38:42<00:00, 47.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0425506830215454, 'eval_runtime': 298.6805, 'eval_samples_per_second': 0.67, 'eval_steps_per_second': 0.084, 'epoch': 1.0}\n",
      "{'train_runtime': 5924.4652, 'train_samples_per_second': 0.169, 'train_steps_per_second': 0.021, 'train_loss': 9.258237518310548, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=9.258237518310548, metrics={'train_runtime': 5924.4652, 'train_samples_per_second': 0.169, 'train_steps_per_second': 0.021, 'total_flos': 65323008000000.0, 'train_loss': 9.258237518310548, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, DataCollatorWithPadding\n",
    "\n",
    "# Prepare data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "# Initialize Trainer with a smaller subset of the dataset\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].select(range(1000)),  # Use a subset of the dataset\n",
    "    eval_dataset=tokenized_datasets[\"validation\"].select(range(200)),  # Use a subset of the dataset\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./arabicaqa_model-base\\\\tokenizer_config.json',\n",
       " './arabicaqa_model-base\\\\special_tokens_map.json',\n",
       " './arabicaqa_model-base\\\\vocab.json',\n",
       " './arabicaqa_model-base\\\\merges.txt',\n",
       " './arabicaqa_model-base\\\\added_tokens.json',\n",
       " './arabicaqa_model-base\\\\tokenizer.json')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the base model\n",
    "model.base_model.save_pretrained(\"./arabicaqa_model-base\")\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(\"./arabicaqa_model-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DifferentialAttention Class\n",
    "class DifferentialAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.qkv_proj = nn.Linear(d_model, d_model * 3)\n",
    "        self.lambda_param = nn.Parameter(torch.tensor(0.8))\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.qkv_proj(x).chunk(3, dim=-1)\n",
    "        q, k, v = qkv\n",
    "        attention_scores = torch.softmax((q @ k.transpose(-2, -1)) / math.sqrt(k.size(-1)), dim=-1)\n",
    "        return attention_scores @ v\n",
    "\n",
    "# Define Custom Output Class\n",
    "@dataclass\n",
    "class CustomCausalLMOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "\n",
    "# Define Custom Model Class\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, base_model, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.differential_attention = DifferentialAttention(d_model, num_heads)\n",
    "        self.vocab_projection = nn.Linear(d_model, base_model.config.vocab_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.base_model(input_ids, attention_mask=attention_mask, labels=labels, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states[-1]  # Last hidden state\n",
    "        attention_output = self.differential_attention(hidden_states)\n",
    "        attention_output = self.vocab_projection(attention_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            print(f\"attention_output shape: {attention_output.shape}\")\n",
    "            print(f\"labels shape: {labels.shape}\")\n",
    "\n",
    "            shift_logits = attention_output[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "            print(f\"shift_logits shape: {shift_logits.shape}\")\n",
    "            print(f\"shift_labels shape: {shift_labels.shape}\")\n",
    "\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            return CustomCausalLMOutput(loss=loss, logits=attention_output)\n",
    "\n",
    "        return CustomCausalLMOutput(logits=attention_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"aubmindlab/aragpt2-base\")\n",
    "base_model.config.output_hidden_states = True  # Enable hidden states\n",
    "\n",
    "# Define Custom Model\n",
    "d_model = base_model.config.hidden_size\n",
    "num_heads = base_model.config.num_attention_heads\n",
    "model = CustomModel(base_model, d_model, num_heads)\n",
    "\n",
    "# Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./QAMODELLLLLL\",  # Save directory\n",
    "    eval_strategy=\"epoch\",           # Evaluate at the end of each epoch\n",
    "    learning_rate=3e-5,              # Adjust learning rate\n",
    "    per_device_train_batch_size=2,   # Reduce batch size\n",
    "    num_train_epochs=3,              # Number of epochs\n",
    "    weight_decay=0.01,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",            # Directory for logs\n",
    "    logging_steps=10,\n",
    "    warmup_steps=100,                # Warmup steps\n",
    "    gradient_accumulation_steps=4,   # Gradient accumulation\n",
    "    fp16=False,                      # Disable mixed precision\n",
    "    no_cuda=False,                   # Enable GPU\n",
    "    run_name=\"ffffffinetuning\" # Experiment name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].select(range(1000)),  # Subset for training\n",
    "    eval_dataset=tokenized_datasets[\"validation\"].select(range(200)),  # Subset for evaluation\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model and Components\n",
    "model.base_model.save_pretrained(\"./arabicaqa_model-base22\")\n",
    "tokenizer.save_pretrained(\"./arabicaqa_model-base22\")\n",
    "torch.save(model.differential_attention.state_dict(), \"./arabicaqa_model-base/differential_attention.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "def generate_answer(question):\n",
    "    # Tokenize the input question\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", max_length=128, truncation=True, padding=\"max_length\").to(model.base_model.device)\n",
    "    \n",
    "    # Generate a response using max_new_tokens\n",
    "    outputs = model.base_model.generate(**inputs, max_new_tokens=50)  # Generate up to 50 new tokens\n",
    "    \n",
    "    # Decode the output to text\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "question =\"Ù…Ø§ Ù‡Ùˆ Ø¹Ø¯Ø¯ Ø³ÙƒØ§Ù† Ø¥Ø³ØªÙˆÙ†ÙŠØ§ØŸ\"\n",
    "answer = generate_answer(question)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
